# Experiment setup {#sec-experiment}

We are interested in generating forecasts to inform the planning horizon of $ph= 42$ days, interested by planners in the ambulance services trust. The forecast horizon in this study is $fh = 2 \times ph$ days ahead (2*42 days planning horizon). This is because the planning is generally frozen for $ph$ days and considering a forecast horizon of $ph$ days might not be helpful for planning. While forecasts are generated for $2 \times ph$ days ahead, performance evaluation is only assessed based on the last $ph$ days and not the $2 \times ph$ days. The forecasts are produced for the holdout of 365 days using time series cross-validation [@hyndman2021forecasting].
In the following section, we discuss the dataset, describe the forecasting methods used to generate base forecasts and present the point and probabilistic accuracy measures.

## Data {#sec-data}

The dataset used in this study is from a major ambulance service trust in the United Kingdom. It contains information relating to the daily number of attended incidents from 10 October 2015 to 31 July 2019 by nature of incidents, priority, the health board managing the service and the control area (or region). Figure @fig-hierarchy depicts both the hierarchical and grouped structure of the data. Figure @fig-hierarchy-1 illustrates the nested hierarchical structure based on control area and health board and Figure @fig-hierarchy-2 shows the grouped structure by priority and the nature of incident.

```{r}
#| label: fig-hierarchy
#| out.width: "60%"
#| fig-cap: "The hierarchical and grouped structure of attended incidents (ambulance demand)"
#| fig-subcap:
#|   - "Hierarchical structure: Attended incidents in all country is disaggregated into 3 control areas /regions and then into 7 different healthboard at the bottom"
#|   - "Grouped structure:  Incidents could be grouped into priority (i.e. Red, Amber & Green) and the nature of attended incident (i.e. there are 35 different nature of incidents including chest pain , breathing problems, heart attack, stroke, and so on). The symbol * refers to the crossed attributes between hierarchical and grouped levels."
#| layout: [[50],[-2], [38]]

library(ggraph)
library(igraph)
library(tidyverse)

data <- data.frame(
  level1="Total",
  level2=c("Central & West", "Central & West","Central & West","North", "South & East","South & East","South & East"),
  level3=c("HD", "SB", "PO", "BC","CV", "CT", "AB")
)
# transform it to a edge list!
edges_level1_2 = data %>% select(level1, level2) %>% 
  unique %>% rename(from=level1, to=level2)
edges_level2_3 = data %>% select(level2, level3) %>% 
  unique %>% rename(from=level2, to=level3)
edge_list=rbind(edges_level1_2, edges_level2_3)

mygraph <- graph_from_data_frame( edge_list )
ggraph(mygraph, layout = 'dendrogram', circular = FALSE) + 
  geom_edge_diagonal() +
  geom_node_point(colour="#dddddd",size=10) +
  geom_node_text(
    aes(label=c("All country", "Central & West", "North","South & East", "HD", "SB", "PO", "BC","CV", "CT", "AB") )
  )+
  theme_void()

knitr::include_graphics(here::here("img/group.png"))
```

Table @tbl-hierarchy also displays the structure of data with the total number of series at each level. At the top level, we have the total attended incidents for the country. We can split these total attended incidents by control area, by health board, by priority or by nature of incident. There are 3 control areas breakdown by 7 local health boards. Attended incident data are categorized into 3 priority classes of red, amber and green. There are also 35 different nature of incidents such as chest pain, stroke, breathing problem, etc. In total, across all levels of disaggregation, there are 1530 time series.

```{r}
#| label: tbl-hierarchy
#| tbl-cap: "Number of time series in each level for the hierarchical & grouped structure of attended incidents"
agg_level <- tibble::tribble(
  ~Level, ~`Number of series`,
  "All country", 1,
  "Control", 3,
  "Health board", 7,
  "Priority", 3,
  "Priority * Control", 9,
  "Priority * Health board", 21,
  "Nature of incident", 35,
  "Nature of incident * Control", 105,
  "Nature of incident * Health board", 245,
  "Priority * Nature of incident", 104,
  "Control * Priority * Nature of incident", 306,
  "Control * Health board * Priority * Nature of incident (Bottom level)", 691,
  "Total", 1530
)
knitr::kable(agg_level, booktabs = T, position = "left") %>% kable_classic(full_width = F)
```

Given the total number of time series, direct visual analysis is infeasible. Therefore, we first compute features of all 1530 time series and display the strength of trend and weekly seasonality strength in Figure @fig-feature. Each point represents one time series with strength of trend in  x-axis and strength of seasonality in y-axis. It is clear that there are some series showing strong trends and/or seasonality, corresponding to series at the higher levels of the hierarchy. The majority show low trend and seasonality with . These are time series belonging to the bottom of the structure, series related to the nature of incidents for each given control, health board and priority.

```{r}
#| label: fig-feature
#| cache: true
#| out.width: "70%"
#| fig.align: center
#| fig-cap: "Time series features of attended incidents across all levels (1530 series)"
library(feasts)
incident_gthf <- read_rds(paste0(storage_folder, "incidents_gt.rds"))
incident_gthf <- read_rds(here::here("data/incident_gt.rds"))
incident_gthf %>% 
  features(incident,feat_stl) %>%
  ggplot(aes(x = trend_strength, y = seasonal_strength_week)) +
  geom_point(pch=1)+
  ggthemes::theme_few()
```

In addition to displaying the trend and seasonality features, we also highlight few time series at various levels of the aggregation. Figure @fig-dataviz reveals different information such as trend, seasonality and noise. For example, some series depict seasonality and trend, whereas some other series report low volume of attended incidents and entropy, making them more volatile and difficult to forecast. At the level on nature of incidents combined with categories of other levels, there are many series that contain zeros with low counts. As such, the data set represents a diverse set of daily time series patterns.

```{r}
#| label: fig-dataviz
#| cache: true
#| dependson: "fig-feature"
#| out.width: "70%"
#| fig-cap: "Time series of attended incidents at various levels"
#| fig-subcap: 
#|   - "all country"
#|   - "Control area"
#|   - "Health board and control area"
#|   - "Healthboard and priority"
#|   - "Nature of incident and health board"
#| layout: [[44,-2, 44], [44,-2, 44], [100]]
p_total <- incident_gthf %>%
    filter(is_aggregated(region) & is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
    autoplot()+
    labs(x="Date", y="Incidents")+
    ggthemes::theme_few()

p_total_control <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>% select(-nature,-category) %>% 
  group_by(date,region) %>% summarise(incidents=sum(incidents), .groups="drop") %>% 
  ggplot(aes(x=date, y= incidents, colour = factor(region))) +
  geom_line()+
  labs(x="Date", y="Incidents", colour = "Control")+
  ggthemes::scale_color_colorblind()+
  ggthemes::theme_few()+
  theme(legend.position = "bottom")

p_control <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>% select(-nature,-category) %>% 
  ggplot(aes(x=date, y= incidents, colour = factor(lhb))) +
  geom_line()+
  facet_wrap(vars(factor(region)), scales = "free_y")+
  labs(x="Date", y="Incidents", colour = "Health board")+
  ggthemes::scale_color_colorblind()+
  ggthemes::theme_few()+
  theme(legend.position = "bottom")

p_priority <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & !is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>% select(-nature,-region) %>% 
  ggplot(aes(x=date, y= incidents, colour = factor(lhb))) +
  geom_line()+
  facet_wrap(vars(factor(category)), scales = "free_y")+
  labs(x="Date", y="Incidents", colour = "Health board")+
  ggthemes::scale_color_colorblind()+
  ggthemes::theme_few()+
  theme(legend.position = "bottom")

selected_nature <- c("CHESTPAIN", "STROKECVA", "BREATHING", "ABDOMINAL")

p_nature_healthboard <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & !is_aggregated(category) & !is_aggregated(nature)) %>% 
as_tibble() %>% mutate(nature=as.character(nature)) %>% 
  filter(nature %in% selected_nature) %>% group_by(date,nature,lhb) %>% summarise(incidents=sum(incidents), .groups="drop") %>% 
  ggplot(aes(x=date, y= incidents, colour = factor(lhb))) +
  geom_line()+
  facet_wrap(vars(factor(nature)), scales = "free_y")+
  labs(x="Date", y="Incidents", colour = "Health board")+
  ggthemes::scale_color_colorblind()+
  ggthemes::theme_few()+
  theme(legend.position = "none")

p_total
p_total_control
p_control
p_priority
p_nature_healthboard
```

## Forecasting methods

Given the presence of various significant patterns in the past attended incidents, we consider three different forecasting models to generate the base forecasts. Once the base forecasts are produced, hierarchical and grouped time series methods are used to reconcile them across the all levels. We briefly discussed forecasting models in the following sections, and the hierarchical forecasting methods are discussed in @sec-htc.

**Naive:** We start with one of the simplest forecasting approaches used in practice - assuming that in the next few days, everything will be the same as in the similar days in the past. This is called "Na√Øve". In our case, given that we need a distribution of values, we will use a modified approach, where the empirical distribution of the daily attended incidents time series is used to forecast the future attended incidents distribution. We consider the empirical distribution of the most recent year of historic data on a rolling basis to capture potential changes in behavior over time.

**Exponential Smoothing State Space model (ETS):** ETS models [@hyndman2021forecasting] can combine trend, seasonality and error components in a time series through various forms such as additive, multiplicative or mixed. The trend component can be none ("N"), Additive ("A"), damped ("Ad") or multiplicative ("M"). The seasonality can be none ("N"), Additive ("A"), or multiplicative ("M"). The error term can also be additive ("A") or multiplicative ("M"). To forecast the attended incidents at each level, we use the `ETS()` function in the `fable` package [@fable2022] in R. To identify the best model for a given time series, the ETS function uses the corrected Akaike‚Äôs Information Criterion (AICc).

<!-- **Auto-Regressive Integrated Moving Average (ARIMA):** ARIMA [@hyndman2021forecasting] is another effective family of forecasting models that capture autocorrelation in time series. They can model various range of time series considering the stationarity of series, the Auto-Regressive (AR) and moving average (MA) orders. In this study, an automatic ARIMA algorithm implemented using `ARIMA()` function of fable package in R is used to forecast the attended incidents. To select the best model for a given time series, the algorithm uses unit root test, Maximum Likelihood Estimation (MLE) and the AICc. -->

**Poisson Regression: ** Despite the popularity and the relevant of automatic `ETS` and `ARIMA` in this study, but they produce non-integer attended incidents and forecasts might also be negative. However, the number of attended incidents is an integer and non-negative. When using `ETS` and `ARIMA`, a time series transformation approach such as `sqrt()` could be used to generate strictly positive forecasts, however forecasts are still not integer. Another alternative is to use  forecasting models that produce integer, non-negative forecasts. One of the models that is frequently used in practice is the Poisson regression [see, for example, @mccarthy2008challenge], which can be summarized as
$$
  \begin{aligned}
    & {y}_t \sim \mathrm{Poisson} \left( \lambda_t \right) \\
    & \log \lambda_t = \mathbf{x}_t' \boldsymbol{\beta}
  \end{aligned} \quad
$$ {#eq-poisson-regression}

The logarithm in @eq-poisson-regression is needed to ensure that the parameter of Poisson distribution is always positive. This model can be estimated via maximization of the likelihood function based on Poisson mass function. For taking into account serial dependence we include a regression on the previous observation. We try to capture the short range serial dependence by a first order autoregressive term and the weekly seasonality by a 7th order autoregressive term. We use the `tscount()` function in the fable package in R, which is a wrapper function written based on `tscount` package. We fit a model to each time series using the function tsglm, with the identity link function, defined by the argument link.

## Performance evaluation

Forecasting performance is evaluated using both point and probabilistic error measures. 

The point forecast accuracy is measured via Root Mean Squared Scaled Error (RMSSE):

$$
\text{RMSSE} = \sqrt{\text{mean}(q_{j}^2)},
$$ {#eq-RMSSE}

where,

$$
q^2_{j} = \frac{\displaystyle e^2_{j}}
    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T (y_{t}-y_{t-m})^2},
$$

$e_{j}$ is the point forecast error $j$ and $m = 1$ for non-seasonal series and $m = 7$ for daily seasonal series, $y_t$ is the observation for period $t$ and $T$ is the sample size (observations used for training the forecasting model). Smaller RMSSE values suggest more accurate forecasts. Note that the measure is scale-independent, thus allowing us to average the results across series.

To measure the forecast distribution performance, we calculate  the Continuous Rank Probability Score [@gneiting2014probabilistic]. It rewards sharpness and penalizes miscalibration, so it measures overall performance. 

$$
CRPS=\frac{1}{h} \sum_{j=1}^{h} \int_{-\infty}^{\infty} \left(F^f_j(x) - F^0_j(x)\right)^2dx
$$ {#eq-CRPS}

where $F^f_j(x)$ is the forecasted Cumulative Density Function (CDF) of period $j$ and ùêπ$F^0_j(x)$ is the true CDF of period $j$.
