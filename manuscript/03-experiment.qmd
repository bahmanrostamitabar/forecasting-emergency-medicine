# Experiment setup {#sec-experiment}

We are interested in generating forecasts to inform the planning horizon of $ph= 42$ days, required by planners in the ambulance services trust. The forecast horizon in this study is $fh = 2 \times ph$ days ahead (2*42 days planning horizon). This is because the planning is generally frozen for $ph$ days and considering a forecast horizon of $ph$ days might not be helpful for planning. While forecasts are generated for $2 \times ph$ days ahead, performance evaluation is only assessed based on the last $ph$ days and not the $2 \times ph$ days. The forecasts are produced for the holdout of 365 days using time series cross-validation [@hyndman2021forecasting].

In the following section, we discuss the dataset, describe the forecasting methods used to generate base forecasts and present the point and probabilistic accuracy measures.

## Data {#sec-data}

The dataset used in this study is from a major ambulance service trust in Great Britain. It contains information relating to the daily number of attended incidents from 1 October 2015 to 31 July 2019, disaggregated by nature of incidents, priority, the health board managing the service and the control area (or region). @fig-hierarchy depicts both the hierarchical and grouped structure of the data. @fig-hierarchy-1 illustrates the nested hierarchical structure based on control area and health board and @fig-hierarchy-2 shows the grouped structure by priority and the nature of incident.

```{r}
#| label: fig-hierarchy
#| out.width: "60%"
#| fig-cap: "The hierarchical and grouped structure of attended incidents (ambulance demand)."
#| fig-subcap:
#|   - "Hierarchical structure: Attended incidents in all country is disaggregated into 3 control areas /regions and then into 7 different healthboard at the bottom"
#|   - "Grouped structure:  Incidents could be grouped into priority (i.e. Red, Amber & Green) and the nature of attended incident (i.e. there are 35 different nature of incidents including chest pain , breathing problems, heart attack, stroke, and so on). The symbol * refers to the crossed attributes between hierarchical and grouped levels."
#| layout: [[50],[-2], [38]]

data <- data.frame(
  level1 = "Total",
  level2 = c("Central & West", "Central & West", "Central & West",
             "North", "South & East", "South & East", "South & East"),
  level3 = c("HD", "SB", "PO", "BC", "CV", "CT", "AB")
)
# transform it to a edge list!
edges_level1_2 <- data %>%
  select(level1, level2) %>%
  unique() %>%
  rename(from = level1, to = level2)
edges_level2_3 <- data %>%
  select(level2, level3) %>%
  unique() %>%
  rename(from = level2, to = level3)
edge_list <- rbind(edges_level1_2, edges_level2_3)

mygraph <- igraph::graph_from_data_frame(edge_list)
ggraph::ggraph(mygraph, layout = "dendrogram", circular = FALSE) +
  ggraph::geom_edge_diagonal() +
  ggraph::geom_node_point(color = "#dddddd", size = 10) +
  ggraph::geom_node_text(
    aes(label = c("All country",
                  "Central & West", "North", "South & East",
                  "HD", "SB", "PO", "BC", "CV", "CT", "AB"))
  ) +
  theme_void()

knitr::include_graphics(here::here("img/group.png"))
```

@tbl-hierarchy also displays the structure of data with the total number of series at each level. At the top level, we have the total attended incidents for the country. We can split these total attended incidents by control area, by health board, by priority or by nature of incident. There are 3 control areas breakdown by 7 local health boards. Attended incident data are categorized into 3 priority classes of red, amber and green. There are also 35 different nature of incidents such as chest pain, stroke, breathing problem, etc. In total, across all levels of disaggregation, there are 1530 time series.

```{r}
#| label: tbl-hierarchy
#| tbl-cap: "Number of time series in each level for the hierarchical & grouped structure of attended incidents"
agg_level <- tibble::tribble(
  ~Level, ~`Number of series`,
  "All country", 1,
  "Control", 3,
  "Health board", 7,
  "Priority", 3,
  "Priority * Control", 9,
  "Priority * Health board", 21,
  "Nature of incident", 35,
  "Nature of incident * Control", 105,
  "Nature of incident * Health board", 245,
  "Priority * Nature of incident", 104,
  "Control * Priority * Nature of incident", 306,
  "Control * Health board * Priority * Nature of incident (Bottom level)", 691,
  "Total", 1530
)
knitr::kable(agg_level, booktabs = TRUE, position = "left") %>%
  kable_classic(full_width = FALSE)
```

Given the total number of time series, direct visual analysis is infeasible. Therefore, we first compute features of all 1530 time series [@m3pca] and display the strength of trend and weekly seasonality strength in @fig-feature. Each point represents one time series with the strength of trend in x-axis and the strength of seasonality in y-axis. It is clear that there are some series showing strong trends and/or seasonality, corresponding to series at the higher levels of the hierarchy. The majority of series show low trend and seasonality. These are time series belonging to the bottom series, series related to the nature of incidents for a given control, health board and priority level. Bottom series are dominated by noise with little or no systematic patterns.

```{r}
#| label: fig-feature
#| cache: true
#| out.width: "70%"
#| fig.align: center
#| fig-cap: "Time series features of attended incidents across all levels (1530 series)"
incident_gthf <- readr::read_rds(here::here("data/incidents_gt.rds"))
incident_gthf %>%
  features(incident, feat_stl) %>%
  ggplot(aes(x = trend_strength, y = seasonal_strength_week)) +
  geom_point(alpha = 0.25) +
  labs(x = "Strength of trend", y = "Strength of weekly seasonality")
```

In addition to displaying the trend and seasonality features, we also visualize few time series at various levels of the aggregation. @fig-dataviz2 reveals different information such as trend, seasonality and noise. For example, some series depict seasonality and trend, whereas some other series report low volume of attended incidents and entropy, making them more volatile and difficult to forecast. At the level on nature of incidents combined with categories of other levels, there are many series that contain zeros with low counts. As such, the data set represents a diverse set of daily time series patterns.

```{r}
#| label: fig-dataviz
#| eval: false
#| include: false
#| dependson: "fig-feature"
#| out.width: "70%"
#| fig-cap: "Time series of attended incidents at various levels."
#| fig-subcap:
#|   - "Whole country"
#|   - "By control area"
#|   - "By health board and control area"
#|   - "By health board and priority"
#|   - "By nature of incident and health board"
#| layout: [[44,-2, 44], [44,-2, 44], [100]]
p_total <- incident_gthf %>%
  filter(is_aggregated(region) & is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  autoplot() +
  labs(x = "Date", y = "Incidents") +
  ggthemes::theme_few()

p_total_control <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>%
  select(-nature, -category) %>%
  group_by(date, region) %>%
  summarise(incident = sum(incident), .groups = "drop") %>%
  ggplot(aes(x = date, y = incident, color = factor(region))) +
  geom_line() +
  labs(x = "Date", y = "Incidents", color = "Control") +
  ggthemes::scale_color_colorblind() +
  ggthemes::theme_few() +
  theme(legend.position = "bottom")

p_control <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>%
  select(-nature, -category) %>%
  ggplot(aes(x = date, y = incident, color = factor(lhb))) +
  geom_line() +
  facet_wrap(vars(factor(region)), scales = "free_y") +
  labs(x = "Date", y = "Incidents", color = "Health board") +
  ggthemes::scale_color_colorblind() +
  ggthemes::theme_few() +
  theme(legend.position = "bottom")

p_priority <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & !is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>%
  select(-nature, -region) %>%
  ggplot(aes(x = date, y = incident, color = factor(lhb))) +
  geom_line() +
  facet_wrap(vars(factor(category)), scales = "free_y") +
  labs(x = "Date", y = "Incidents", color = "Health board") +
  ggthemes::scale_color_colorblind() +
  ggthemes::theme_few() +
  theme(legend.position = "bottom")

selected_nature <- c("CHESTPAIN", "STROKECVA", "BREATHING", "ABDOMINAL")

p_nature_healthboard <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & !is_aggregated(category) & !is_aggregated(nature)) %>%
  as_tibble() %>%
  mutate(nature = as.character(nature)) %>%
  filter(nature %in% selected_nature) %>%
  group_by(date, nature, lhb) %>%
  summarise(incident = sum(incident), .groups = "drop") %>%
  ggplot(aes(x = date, y = incident, color = factor(lhb))) +
  geom_line() +
  facet_wrap(vars(factor(nature)), scales = "free_y") +
  labs(x = "Date", y = "Incidents", color = "Health board") +
  ggthemes::scale_color_colorblind() +
  ggthemes::theme_few() +
  theme(legend.position = "none")

p_total
p_total_control
p_control
p_priority
p_nature_healthboard
```


```{r}
#| label: fig-dataviz2
#| dependson: "fig-feature"
#| out.width: "100%"
#| fig-width: 8
#| fig-height: 10
#| fig-cap: "Time series of attended incidents at various levels."
no_x_axis <- theme(axis.title.x=element_blank(),
                   axis.text.x=element_blank(),
                   axis.ticks.x=element_blank())
p_total <- incident_gthf %>%
  filter(is_aggregated(region) & is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  autoplot(incident) +
  labs(x = "", y = "Incidents") +
  no_x_axis

p_control <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>%
  select(-nature, -category) %>%
  group_by(date, region) %>%
  summarise(incident = sum(incident), .groups = "drop") %>%
  ggplot(aes(x = date, y = incident, color = factor(region))) +
  geom_line() +
  labs(y = "Incidents", color = "Control")  +
  no_x_axis

p_board <- incident_gthf %>%
  filter(!is_aggregated(region) & !is_aggregated(lhb) & is_aggregated(category) & is_aggregated(nature)) %>%
  as_tibble() %>%
  select(-nature, -category) %>%
  ggplot(aes(x = date, y = incident, color = factor(lhb))) +
  geom_line() +
  #facet_wrap(vars(factor(region)), scales = "free_y") +
  labs(y = "Incidents", color = "Health board") +
  no_x_axis

p_priority <- incident_gthf %>%
  filter(is_aggregated(region) & is_aggregated(lhb) & !is_aggregated(category) & is_aggregated(nature)) %>%
  mutate(
    category = recode(category, RED = "Red", AMB = "Amber", GRE = "Green"),
    category = factor(category, levels=c("Red","Amber","Green"))
  ) |>
  as_tibble() %>%
  select(-nature, -region) %>%
  ggplot(aes(x = date, y = incident, color = factor(category))) +
  geom_line() +
  scale_color_manual(values = c(Red="#ff3300", Amber = "#E69f00", Green="#009e73")) +
  labs(y = "Incidents", color = "Priority") +
  no_x_axis

selected_nature <- c("CHESTPAIN", "STROKECVA", "BREATHING", "ABDOMINAL")
p_nature <- incident_gthf %>%
  filter(is_aggregated(region) & is_aggregated(lhb) & is_aggregated(category) & !is_aggregated(nature)) %>%
  as_tibble() %>%
  mutate(nature = as.character(nature)) %>%
  filter(nature %in% selected_nature) %>%
  group_by(date, nature, lhb) %>%
  summarise(incident = sum(incident), .groups = "drop") %>%
  ggplot(aes(x = date, y = incident, color = nature)) +
  geom_line() +
  labs(x = "Date", y = "Incidents", color = "Nature of incident")

p_total /
p_control /
p_board /
p_priority /
p_nature
```


We consider several forecasting models that account for the diverse patterns of the time series across the entire hierarchy. In developing the forecasting models, the time series of holidays are also used in addition to the attended incidents. We use public holidays, school holidays and Christmas Day and New Year's Day as predictors of incident attended. These type of holidays will  affect peoples' activities and may increase or decrease the number of attended incidents.

## Forecasting methods

Given the presence of various significant patterns in the past attended incidents, we consider three different forecasting models to generate the base forecasts. Once the base forecasts are produced, hierarchical and grouped time series methods are used to reconcile them across the all levels. We briefly discussed forecasting models in the following sections, and the hierarchical forecasting methods are discussed in @sec-htc.

**Naive:** We start with a simple forecasting approach, assuming that the future days will be similar to past days. We use the empirical distribution of the past daily attended incidents to create the forecast distribution of future attended incidents. We consider the empirical distribution of the most recent year of historic data on a rolling basis to capture potential changes in behavior over time.\todo{Actually we use all the data.}

**Exponential Smoothing State Space model (ETS):** ETS models [@hyndman2021forecasting] can combine trend, seasonality and error components in a time series through various forms such as additive, multiplicative or mixed. The trend component can be none ("N"), Additive ("A"), damped ("Ad") or multiplicative ("M"). The seasonality can be none ("N"), Additive ("A"), or multiplicative ("M"). The error term can also be additive ("A") or multiplicative ("M"). To forecast the attended incidents at each level, we use the `ETS()` function in the `fable` package [@fable2022] in R. To identify the best model for a given time series, the ETS function uses the corrected Akaike’s Information Criterion (AICc).

Despite the popularity and the relevance of automatic `ETS` in this study, however it may produce forecast distributions that are non-integer and include negative values, despite the number of attended incidents being integer and non-negative. When using `ETS`, a time series transformation approach could be used to generate strictly positive forecasts, although forecast distributions will still be non-integer. An alternative is to use  forecasting models that produce integer, non-negative forecasts. in the following section we present Generalized Linear Models (GLMs) and Poisson Regression to produce count base forecasts.

**Generalized Linear Model (GLM):** GLMs are a family of models developed to extend the concept of linear regression models. They perform a regression by modeling the response variable as coming from a particular member of the exponential family, and then transforming the mean of the response so that the transformed mean is a linear function of the predictors. One of the models that is frequently used in practice to generate count forecasts is the Poisson regression. We will consider forecasting attended incidents using the covariates spline trend,  day of the week dummy variables (from Monday to Sunday), Fourier terms to capture yearly seasonality, public holidays (1 when is public holiday, 0 otherwise), school holidays (1 when is school holiday, 0 otherwise) and Christmas Day (1 when is Christmas Day, 0 otherwise) and New Year's Day (1 when is New Year's Day, 0 otherwise). We fit a Poisson regression model using the function `glm()` from the package in R, with the argument `family = poisson` to specify that we wish to fit a Poisson regression model.

<<<<<<< HEAD
**Poisson Regression using tscount: ** We consider another Poisson regression model that takes into account serial dependence in addition to covariates used in the GLM model. To that end, we use `tsglm()` function in _tscount_ package in R [@JSSv082i05] to model the attended incidents. The logarithmic link function is used to ensure that the parameter of Poisson distribution is always positive. This model can be estimated via maximization of the likelihood function based on Poisson mass function. The regression model captures the short range serial dependence by including the three order autoregressive terms.
=======
**Poisson Regression using tscount:** We consider another Poisson regression model that takes into account serial dependence in addition to covariates used in the GLM model. To that end, we use `tsglm()` function in _tscount_ package in R to model the attended incidents. The logarithmic link function is used to ensure that the parameter of Poisson distribution is always positive. This model can be estimated via maximization of the likelihood function based on Poisson mass function. The regression model captures the short range serial dependence by including the three order autoregressive terms.
>>>>>>> 5a237cc838765e1f36fcf983d11f30d8f9f711db

**Ensemble method:** we also use an ensemble method that combines forecasts generated from Naive, ETS, GLM and Poisson regression to form a mixture distribution [@combinations].

<!-- add a sentence to describe how the point forecast and forecast distribution is created for the ensemble -->

## Performance evaluation

To evaluate the performance of the various forecasting approaches, we split the data into a series of ten training and test sets. We use a time series cross-validation approach [@hyndman2021forecasting], with a forecast horizon of 84 days, and each training set expanding in 42-day steps. The first training set uses all data up to 2018-04-25, and the first test set uses the 84 days beginning 2018-04-26. The second training set uses all data up to 2018-06-06, with the second test set using the following 84 days. The largest training set ends on 2019-05-09, with the test set ending on 2019-07-31. Model development and hyper-parameter tuning is performed using the training data only. Forecasting performance is evaluated using both point and probabilistic error measures. While we compute forecast errors for the entire 12 weeks, we are most interested in the last 42 days of each test set, because that corresponds to  how forecasts are generated for planning in practice. Forecasting performance is evaluated using both point and probabilistic error measures. 

Point forecast accuracy is measured via the Mean Squared Scaled Error (MSSE) and the Mean Absolute Scaled Error (MASE). The Mean Absolute Scaled Error (MASE) [@HK06] is calculated as:
$$
  \text{MASE} = \text{mean}(|q_{j}|),
$$
where
$$
  q_{j} = \frac{ e_{j}}
    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T |y_{t}-y_{t-m}|},
$$
and $e_{j}$ is the point forecast error for forecast horizon $j$, $m = 7$ (as we have daily seasonal series), $y_t$ is the observation for period $t$, and $T$ is the sample size (the number of observations used for training the forecasting model). The denominator is the mean absolute error of the seasonal naive method in the fitting sample of $T$ observations and is used to scale the error. Smaller MASE values suggest more accurate forecasts. Note that the measure is scale-independent, thus allowing us to average the results across series. 

A related measure is MSSE [@hyndman2021forecasting], which uses squared errors rather than absolute errors:
$$
  \text{MSSE} = \text{mean}(q_{j}^2),
$$ {#eq-RMSSE}
where,
$$
  q^2_{j} = \frac{ e^2_{j}}
    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T (y_{t}-y_{t-m})^2},
$$
Again, this is scale-independent, and smaller MSSE values suggest more accurate forecasts. 

To measure the forecast distribution accuracy, we calculate the Continuous Rank Probability Score [@gneiting2014probabilistic]. It rewards sharpness and penalizes miscalibration, so it measures overall performance of the forecast distribution.
$$
  \text{CRPS} = \text{mean}(p_j),
$$ {#eq-CRPS}
where
$$
  p_j = \int_{-\infty}^{\infty} \left(G_j(x) - F_j(x)\right)^2dx,
$$
where $G_j(x)$ is the forecasted probability distribution function for forecast horizon $j$, and $F_j(x)$ is the true probability distribution function for the same period. 
