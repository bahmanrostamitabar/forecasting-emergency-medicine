% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  authoryear,
  preprint,
  3p]{elsarticle}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{todonotes,mathtools,bm,amsmath}
\mathtoolsset{showonlyrefs}
\usepackage{mathpazo}
\setlength{\parindent}{0cm}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\journal{Annals of Emergency Medicine}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{elsarticle-harv}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Hierarchical Time Series Forecasting in Emergency Medical Services},
  pdfauthor={Bahman Rostami-Tabar; Rob J. Hyndman},
  pdfkeywords={healthcare, emergency services, forecast
reconciliation, ambulance demand, regression},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\begin{document}

\begin{frontmatter}
\title{Hierarchical Time Series Forecasting in Emergency Medical
Services}
\author[1]{Bahman Rostami-Tabar%
\corref{cor1}%
}
 \ead{rostami-tabarb@cardiff.ac.uk} 
\author[2]{Rob J. Hyndman%
%
}
 \ead{Rob.Hyndman@monash.edu} 

\affiliation[1]{organization={Cardiff University, Cardiff Business
School},country={United Kingdom},countrysep={,},postcode={CF10
3EU},postcodesep={}}
\affiliation[2]{organization={Monash University, Department of
Econometrics and Business
Statistics},country={Australia},countrysep={,},postcode={VIC
3800},postcodesep={}}

\cortext[cor1]{Corresponding author}


        
\begin{abstract}
Accurate forecasts of ambulance demand are crucial inputs when planning
and deploying staff and fleet. Such demand forecasts are required at
national, regional and sub-regional levels, and must take account of the
nature of incidents and their priorities. These forecasts are often
generated independently by different teams within the organization. As a
result, forecasts at different levels may be inconsistent, resulting in
conflicting decisions and a lack of coherent coordination in the
service. To address this issue, we exploit the hierarchical and grouped
structure of the demand time series, and apply forecast reconciliation
methods to generate both point and probabilistic forecasts that are
coherent and use all the available data at all levels of disaggregation.
The methods are applied to daily incident data from an ambulance service
in Great Britain, from October 2015 to July 2019, disaggregated by
nature of incident, priority, managing health board, and control area.
We use an ensemble of forecasting models, and show that the resulting
forecasts are better than any individual forecasting model. We validate
the forecasting approach using time-series cross-validation.
\end{abstract}





\begin{keyword}
    healthcare \sep emergency services \sep forecast
reconciliation \sep ambulance demand \sep 
    regression
\end{keyword}
\end{frontmatter}
    \ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[interior hidden, frame hidden, boxrule=0pt, borderline west={3pt}{0pt}{shadecolor}, enhanced, sharp corners, breakable]}{\end{tcolorbox}}\fi

\hypertarget{sec-intro}{%
\section{Introduction}\label{sec-intro}}

A failure to match available resources to demand in Emergency Medical
Services (EMS) results in patient flow problems, with serious
consequences for patients, staff and the entire care system
\citep{ekstrom2015forecasting, ROSTAMITABAR20221197}. Demand forecasting
in EMS helps service planners to avoid the mismatch, potentially
providing massive savings in costs and lives, and leading to better
patient outcomes. Accurate daily demand forecasting enables planners and
decision makers to manage resources to meet anticipated patients,
reconfigure units, and redeploy staff and vehicles as necessary.

Demand forecasts at EMS are typically required at multiple levels of an
organization to inform various planning and decision-making processes
\citep{hulshof2012taxonomic}. There are some planning process at the
national level (strategic and long-term) such as workforce resource
planning and budgeting; sub-national, regional or healthcare level
(tactical and medium-term) such as temporary capacity expansions,
resource sharing and staff-shift scheduling; and hospital or station
level (operational and short-term) such as planning rosters for staff
and ambulance deployment. Demand forecasts might also be required at
different levels for a specific area of interest such as the nature of
demand or the priority level. Moreover, the time series data in EMS has
an inherent hierarchical and grouped structure to support such
forecasting requirements. Demand for emergency medical services at the
country level can be disaggregated in a geographical hierarchy into
sub-national, regions, health boards, and stations/hospitals, or divided
into groups such as the nature of incidents or demand priority.
Therefore, using forecasting methodologies that account for hierarchical
and/or grouped structures of time series in EMS is a natural fit.

However, despite a large number of studies dedicated to forecasting for
EMS
\citep{mingliterature2022, gul2020exhaustive, ibrahim2016modeling, wargon2009systematic},
the hierarchical data structure has been largely ignored, and the main
focus has been on producing independent forecasts at a single level.
Generating independent forecasts can result in a lack of consistency and
coordination, and therefore leads to less effective planning and
decision making. With hierarchical forecasting, plans at any level are
based on coherent forecasts and therefore can be aligned. Implementing
and sustaining improvements in EMS require alignments and coordination
between different stakeholders, without which teams operate in isolation
leading to conflicts, duplication work, rework, or work that runs
counter to the overall goal to improve the quality of delivery service.
Hierarchical forecasting framework can be used as a tool to improve
coordination between teams across the care services at the national,
sub-national, regional and local levels. The hierarchical forecasting
approaches not only create consistent forecasts, but are usually also
more accurate than the independent (base) forecasts
\citep{hyndman2011optimal}. To our knowledge, there has been no previous
research involving hierarchical and grouped forecasting in the entire
field of forecasting for healthcare management.

In this paper, we address this gap by investigating the application of
hierarchical forecasting approaches in the EMS using daily time series
of verified incidents from 2015 to 2020 in a major ambulance service in
Great Britain. The data has hierarchical and grouped structures, with
hierarchies at the national, control (i.e.~sub-national), health board
(i.e.~regional) levels, as well as groups by priority and nature of
incidents. We produce consistent point forecasts and forecast
distributions for all levels, which is critical for an effective
planning and associated risk management. We compare the point and
probabilistic forecast accuracy of the independent forecasts, bottom-up
and optimal reconciliation approaches. We first generate
independent/base forecasts using Exponential Smoothing State Space
(ETS), Generalized Linear Model (GLM), Poisson regression, a simple
empirical distribution and an ensemble method, followed by applying
bottom-up and optimal reconciliation approaches. Forecast performance is
assessed by the Mean Squared Scaled Error (MSSE) for point forecasts and
Continuous Ranked Probability Scores (CRPS) for the probabilistic
forecasts. This paper complies with reproducibility principles
\citep{stodden2013best, boylan2015reproducibility}, and can be applied
to any healthcare service (e.g., emergency department, primary or social
care) subject to the time series having a hierarchical and/or grouped
structure.

The remainder of this article is structured as follows: In
Section~\ref{sec-lit}, we provide a brief review of the literature and
discuss its limitation to position our work; in
Section~\ref{sec-experiment}, we present the experiment design
describing the data set, forecasting methods and forecast evaluation
metrics. In Section~\ref{sec-htc}, we discuss the hierarchical time
series forecasting approaches to generate both point and probabilistic
forecasts. In Section~\ref{sec-results}, we present and discuss our
results; in Section~\ref{sec-conclusion}, we summarize our findings and
present ideas for future research.

\hypertarget{sec-lit}{%
\section{Research background}\label{sec-lit}}

Emergency medical services (EMS) are a critical component in the
delivery of urgent medical care to communities. An effective service
delivery requires accurate resource planning that generally relies on
demand forecasts at operational, tactical and strategic levels.

There is a substantial number of studies on the application of time
series forecasting in the Emergency Medical Services. For example,
\citet{ibrahim2016modeling} provide an extensive review of the models
used in forecasting call volume arrivals. Another important area is
related to forecasting ambulance demand. Although the definition of
demand might not be always clearly stated, this is typically referring
to a situation where a physical resource has been deployed to respond to
an incident. This might be also called \emph{attended incidents}.
Another demand related variable is verified incidents; these are all
incidents that require an action: either by sending a physical vehicle,
responding via the Clinical Support Desk, requesting an external
provider to respond to it, or forwarding it to other channels such as
police, firefighters or general practitioners. Our study is aligned with
this stream of the literature. Another similar area that has received
considerable attention is Emergency Department forecasting; we refer
interested readers to \citet{mingliterature2022},
\citet{gul2020exhaustive} and \citet{wargon2009systematic} for extensive
reviews of the relevant literature. Although crucial to EMS performance,
\citet{aringhieri2017emergency} state that demand forecasting has
received limited research attention in the EMS context. In this section,
we provide a brief review of studies on forecasting ambulance demand in
EMS.

There are generally two main streams of research related to forecasting
ambulance demand in EMS: (i) the first stream focuses on the application
of time series methods and regression approaches to forecasting
aggregate ambulance demand \citep{vile2012predicting, sasaki2010using};
and (ii) the second stream considers forecasting EMS demand in finer
temporal and geographical granularities by employing temporal-spatial
prediction methods \citep{zhou2016predicting, zhou2016predictinglit}.
The focus of our study is related to the first stream of research.

\citet{sasaki2010using} develop a multivariable regression model to
estimate future EMS demands. In addition to the historical demand, the
population census for different age groups and counts of the number of
companies employing more than five people are included in the
regression. The census variables describe groups who are more likely to
need an ambulance. A stepwise ordinary least squares regression analysis
is used for estimating the parameter and generating forecast. The only
performance measure reported in this study is \(R^2\), which is not an
effective measure of forecast accuracy \citep[p457]{armstrong01}. The
research design of this study is not rigorous and the study is not
reproducible. \citet{vile2012predicting} explore using a Singular
Spectrum Analysis (SSA) method to generate forecasts of the EMS demand
at the national level for 7-day, 14-day, 21-day and 28-day forecast
horizons using data provided by an ambulance service in Great Britain.
The performance of this approach is compared to Auto-Regressive
Integrated Moving Average (ARIMA) and Holt-Winters time series methods
using Root Mean Squared Error (RMSE). They concluded that point
forecasts generated by SSA are more accurate for longer-term, but that
ARIMA and Holt-Winters performance is superior for shorter-term
horizons. \citet{vile2016time} further develop a decision support system
to integrate forecasts generated by SSA. However, the study does not
compare and contrast the performance of forecasting methods based on
utility measures such as cost, resource utilization or response time.
The tool contains options that allow generating forecasts at various
levels of granularity, however, it ignores the hierarchical and grouped
relationships structure, preventing aligned decision making and
coordination.

\citet{9659837} investigate forecasting EMS demand in a high
spatio-temporal resolution of 1km\(^2\) spatial regions and 1-hr time
intervals using total incidents in Oslo, Norway, from 1 January 2015 to
11 February 2019. They used multi-layer perceptron (MLP) and long
short-term memory (LSTM) models to forecast the EMS demand, and compare
the results to simple aggregation methods and baselines. The point
forecast accuracy is evaluated using Mean Absolute Error (MAE) and Mean
Squared Error (MSE), and the forecast distribution is measured by
Categorical Cross-Entropy. They found that Neural Network models
performed better in producing point forecasts, while a distribution
baseline method based on spatial distribution of the incidents across
all time steps provided more accurate forecast distributions.
\citet{zhou2016predictinglit} proposed three methods based on Gaussian
mixture models, kernel density estimation, and kernel warping to predict
hourly data 4 weeks ahead for a 1km\(^2\) spatial region. Two years of
incidents from Toronto, Canada (years 2007 and 2008 with 391,296 events)
and Melbourne, Australia (years 2011 and 2012 with 696,975 events) were
used to build the model and examine the performance on test data using
mean negative log likelihood. They show that forecasts generated by the
proposed methods were significantly more accurate than the current
industry practice (a simple averaging formula).
\citet{grekousis2019will} investigated the combination of spatial
analysis methods with data mining techniques based on an improved
Hungarian algorithm and a MLP neural network to identify the most likely
locations of future emergency events. The proposed approach was tested
using data of 2851 events attended by the EMS in Athens, Greece, over 24
weeks. They showed that 23\% of real emergency events lie within 50
meters of the predicted ones and nearly 70\% of the real emergency
events lie no further than 150 meters away, which is rather accurate
given the granularity of the problem at the city level.

We note a number of limitations in the literature of EMS forecasting,
that encourage us to undertake this research. These limitations are
summarized as following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Current studies ignore the inherent hierarchical and/or grouped
  structure of the time series data, and the relationship between series
  at different levels of hierarchy. This may result in incoherent
  forecasts leading to misaligned planning and decision making. While
  the hierarchical forecasting methodology has been developed and
  applied in various domains over the past 10 years
  \citep{panagiotelis2022probabilistic}, it has never been explored in
  this area.
\item
  Current research is mainly concerned with generating point forecasts
  at a single level of hierarchy. There is a lack of studies considering
  the entire forecast distribution of daily ambulance demand for the
  whole hierarchy to inform the decision-making process and to better
  represent the uncertainty of future demand, providing a risk
  management tool for planners.
\item
  Reproducibility is still a major challenge in EMS forecasting, as it
  is unlikely that any reader can reproduce prior studies without the
  help of the authors of those papers.
\item
  Another limitation is related to the generated forecasts not being on
  the sample space of non-negative counts. Since actual ambulance counts
  cannot be negative or non-integer, ambulance demand forecast
  distributions should reflect the data. Of course, point forecasts
  represent means, so they should be non-negative, but may be
  non-integer. While this might not be an issue when producing forecasts
  at a single level, producing non-negative count forecasts in a
  hierarchical/grouped structure is challenging and requires further
  investigation in the future.
\end{enumerate}

This paper concerns the problem of hierarchical forecasting in EMS and
generates and evaluates both point and probabilistic forecast across
different levels of the hierarchy, hence addressing some important gaps
identified in the literature.

\hypertarget{sec-experiment}{%
\section{Experiment setup}\label{sec-experiment}}

We are interested in generating forecasts to inform the planning horizon
of 42 days, required by planners in the ambulance service. The forecast
horizon in this study is \(2 \times 42 = 84\) days ahead, because the
planning is generally frozen for 42 days and so forecasts of the next 42
days is not particularly helpful for planning. While forecasts are
generated for 84 days ahead, performance evaluation is only assessed
based on the last 42 days and not the whole forecast period. The
forecasts are produced for various training and test sets using time
series cross-validation \citep{hyndman2021forecasting}.

In the following section, we discuss the dataset, describe the
forecasting methods used to generate base forecasts, and present the
point and probabilistic accuracy measures.

\hypertarget{sec-data}{%
\subsection{Data}\label{sec-data}}

The dataset used in this study is from a major ambulance service in
Great Britain. It contains information relating to the daily number of
attended incidents from 1 October 2015 to 31 July 2019, disaggregated by
nature of incidents, priority, the health board managing the service and
the control area (or region). Figure~\ref{fig-hierarchy} depicts both
the hierarchical and grouped structure of the data.
Figure~\ref{fig-hierarchy-1} illustrates the nested hierarchical
structure based on control area and health board and
Figure~\ref{fig-hierarchy-2} shows the grouped structure by priority and
the nature of incident.

\begin{figure}

\begin{minipage}[t]{0.56\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{main_files/figure-pdf/fig-hierarchy-1.pdf}

}

}

\subcaption{\label{fig-hierarchy-1}Hierarchical structure: Attended
incidents in all country is disaggregated into 3 control areas /regions
and then into 7 different healthboard at the bottom}
\end{minipage}%
%
\begin{minipage}[t]{0.02\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.42\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{/Users/bahmanrostami-tabar/Documents/1-research/1-research_papers/Work with Rob Hyndman/forecasting-emergency-medcine/img/group.png}

}

}

\subcaption{\label{fig-hierarchy-2}Grouped structure: Incidents could be
grouped into priority (i.e.~Red, Amber \& Green) and the nature of
attended incident (i.e.~there are 35 different nature of incidents
including chest pain , breathing problems, heart attack, stroke, and so
on). The symbol * refers to the crossed attributes between hierarchical
and grouped levels.}
\end{minipage}%

\caption{\label{fig-hierarchy}The hierarchical and grouped structure of
attended incidents (ambulance demand).}

\end{figure}

Table~\ref{tbl-hierarchy} also displays the structure of data with the
total number of series at each level. At the top level, we have the
total attended incidents for the country. We can split these total
attended incidents by control area, by health board, by priority or by
nature of incident. There are 3 control areas breakdown by 7 local
health boards. Attended incident data are categorized into 3 priority
classes of red, amber and green. There are also 35 different nature of
incidents such as chest pain, stroke, breathing problem, etc. In total,
across all levels of disaggregation, there are 1530 time series.

\hypertarget{tbl-hierarchy}{}
\begin{table}
\caption{\label{tbl-hierarchy}Number of time series in each level for the hierarchical \& grouped
structure of attended incidents }\tabularnewline

\centering
\begin{tabular}{lr}
\toprule
Level & Number of series\\
\midrule
All country & 1\\
Control & 3\\
Health board & 7\\
Priority & 3\\
Priority * Control & 9\\
\addlinespace
Priority * Health board & 21\\
Nature of incident & 35\\
Nature of incident * Control & 105\\
Nature of incident * Health board & 245\\
Priority * Nature of incident & 104\\
\addlinespace
Control * Priority * Nature of incident & 306\\
Control * Health board * Priority * Nature of incident (Bottom level) & 691\\
Total & 1530\\
\bottomrule
\end{tabular}
\end{table}

Given the total number of time series, direct visual analysis is
infeasible. Therefore, we first compute features of all 1530 time series
\citep{m3pca} and display the strength of trend and weekly seasonality
strength in Figure~\ref{fig-feature}. Each point represents one time
series with the strength of trend in x-axis and the strength of
seasonality in y-axis. Both measures are on a scale of {[}0,1{]}. It is
clear that there are some series showing strong trends and/or
seasonality, corresponding to series at the higher levels of the
hierarchy. The majority of series show low trend and seasonality. These
are time series belonging to the bottom series, series related to the
nature of incidents for a given control, health board and priority
level. Bottom series are dominated by noise with little or no systematic
patterns.

\begin{figure}

{\centering \includegraphics[width=0.7\textwidth,height=\textheight]{main_files/figure-pdf/fig-feature-1.pdf}

}

\caption{\label{fig-feature}Time series features of attended incidents
across all levels (1530 series)}

\end{figure}

In addition to displaying the trend and seasonality features, we also
visualize few time series at various levels of the aggregation.
Figure~\ref{fig-dataviz2} reveals different information such as trend,
seasonality and noise. For example, some series depict seasonality and
trend, whereas some other series report low volume of attended incidents
and entropy, making them more volatile and difficult to forecast. At the
level on nature of incidents combined with categories of other levels,
there are many series that contain zeros with low counts. As such, the
data set represents a diverse set of daily time series patterns.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{main_files/figure-pdf/fig-dataviz2-1.pdf}

}

\caption{\label{fig-dataviz2}Time series of attended incidents at
various levels. The panels show data from the whole country, by control
area, by health board, by priority level, and by nature of incident.
Only four of the 35 nature of incident categories are shown to avoid too
much overplotting.}

\end{figure}

We consider several forecasting models that account for the diverse
patterns of the time series across the entire hierarchy. In developing
the forecasting models, the time series of holidays are also used in
addition to the attended incidents. We use public holidays, school
holidays and Christmas Day and New Year's Day as predictors of incident
attended. These type of holidays will affect peoples' activities and may
increase or decrease the number of attended incidents.

\hypertarget{forecasting-methods}{%
\subsection{Forecasting methods}\label{forecasting-methods}}

Given the presence of various significant patterns in the past attended
incidents, we consider three different forecasting models to generate
the base forecasts. Once the base forecasts are produced, hierarchical
and grouped time series methods are used to reconcile them across all
levels. We briefly discuss forecasting models in the following sections,
and the hierarchical forecasting methods are discussed in
Section~\ref{sec-htc}.

\textbf{Naive:} We start with a simple forecasting approach, assuming
that the future days will be similar to past days. We use the empirical
distribution of the past daily attended incidents to create the forecast
distribution of future attended incidents.

\textbf{Exponential Smoothing State Space model (ETS):} ETS models
\citep{hyndman2021forecasting} can combine trend, seasonality and error
components in a time series through various forms that can be additive,
multiplicative or mixed. The trend component can be none (``N''),
Additive (``A'') or damped (``Ad''); the seasonality can be none
(``N''), Additive (``A''), or multiplicative (``M''); and the error term
can be additive (``A'') or multiplicative (``M''). To forecast the
attended incidents at each level, we use the \texttt{ETS()} function in
the \texttt{fable} package \citep{fable2022} in R. To identify the best
model for a given time series, the \texttt{ETS} function uses the
corrected Akaike's Information Criterion (AICc).

Despite the popularity and the relevance of automatic \texttt{ETS} in
this study, it may produce forecast distributions that are non-integer
and include negative values, although the number of attended incidents
is always integer and non-negative. When using \texttt{ETS}, a time
series transformation approach could be used to generate strictly
positive forecasts, although forecast distributions will still be
non-integer. An alternative is to use forecasting models that produce
integer, non-negative forecasts. In the following section we present
Generalized Linear Models (GLMs) and Poisson time series regression to
produce count base forecasts.

\textbf{Generalized Linear Model (GLM):} GLMs are a family of models
developed to extend the concept of linear regression models to
non-Gaussian distributions \citep{Faraway2016}. They model the response
variable as a particular member of the exponential family, with the mean
being a transformation of a linear function of the predictors. One of
the models that is frequently used in practice to generate count
forecasts is Poisson regression. We will consider forecasting attended
incidents using the covariates spline trend, day of the week dummy
variables (from Monday to Sunday), Fourier terms to capture yearly
seasonality, public holidays (1 when is public holiday, 0 otherwise),
school holidays (1 when is school holiday, 0 otherwise) and Christmas
Day (1 when is Christmas Day, 0 otherwise) and New Year's Day (1 when is
New Year's Day, 0 otherwise). We fit a Poisson regression model using
the function \texttt{glm()} from the \emph{stats} package in R, with the
argument \texttt{family\ =\ poisson} to specify that we wish to fit a
Poisson regression model with a log link function.

\textbf{Poisson Regression using tscount (TSGLM):} We also consider
another Poisson regression model that takes into account serial
dependence, using the \texttt{tsglm()} function in the \emph{tscount}
package in R \citep{JSSv082i05} to model the attended incidents. Again,
the logarithmic link function is used to ensure that the parameter of
Poisson distribution is always positive. This model captures the short
range serial dependence by including three autoregressive terms, in
addition to the same covariates that were used in the GLM model. To
distinguish this from the previous GLM model, we will refer to this
model as ``TSGLM''.

\textbf{Ensemble method:} Finally, we use an ensemble method that
combines the forecasts generated from the Naive, ETS, GLM and TSGLM
models to form a mixture distribution \citep{combinations}.

\hypertarget{performance-evaluation}{%
\subsection{Performance evaluation}\label{performance-evaluation}}

To evaluate the performance of the various forecasting approaches, we
split the data into a series of ten training and test sets. We use a
time series cross-validation approach \citep{hyndman2021forecasting},
with a forecast horizon of 84 days, and each training set expanding in
42-day steps. The first training set uses all data up to 2018-04-25, and
the first test set uses the 84 days beginning 2018-04-26. The second
training set uses all data up to 2018-06-06, with the second test set
using the following 84 days. The largest training set ends on
2019-05-09, with the test set ending on 2019-07-31. Model development
and hyper-parameter tuning is performed using the training data only.
While we compute forecast errors for the entire 12 weeks, we are most
interested in the last 42 days of each test set, because that
corresponds to how forecasts are generated for planning in practice.
Forecasting performance is evaluated using both point and probabilistic
error measures.

Point forecast accuracy is measured via the Mean Squared Scaled Error
(MSSE) and the Mean Absolute Scaled Error (MASE). The Mean Absolute
Scaled Error (MASE) \citep{HK06} is calculated as: \[
  \text{MASE} = \text{mean}(|q_{j}|),
\] where \[
  q_{j} = \frac{ e_{j}}
 {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T |y_{t}-y_{t-m}|},
\] and \(e_{j}\) is the point forecast error for forecast horizon \(j\),
\(m = 7\) (as we have daily seasonal series), \(y_t\) is the observation
for period \(t\), and \(T\) is the sample size (the number of
observations used for training the forecasting model). The denominator
is the mean absolute error of the seasonal naive method in the fitting
sample of \(T\) observations and is used to scale the error. Smaller
MASE values suggest more accurate forecasts. Note that the measure is
scale-independent, thus allowing us to average the results across
series.

A related measure is MSSE \citep{hyndman2021forecasting}, which uses
squared errors rather than absolute errors:
\begin{equation}\protect\hypertarget{eq-RMSSE}{}{
  \text{MSSE} = \text{mean}(q_{j}^2),
}\label{eq-RMSSE}\end{equation} where, \[
  q^2_{j} = \frac{ e^2_{j}}
 {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T (y_{t}-y_{t-m})^2},
\] Again, this is scale-independent, and smaller MSSE values suggest
more accurate forecasts.

To measure the forecast distribution accuracy, we calculate the
Continuous Rank Probability Score \citep{gneiting2014probabilistic}. It
rewards sharpness and penalizes miscalibration, so it measures overall
performance of the forecast distribution.
\begin{equation}\protect\hypertarget{eq-CRPS}{}{
  \text{CRPS} = \text{mean}(p_j),
}\label{eq-CRPS}\end{equation} where \[
  p_j = \int_{-\infty}^{\infty} \left(G_j(x) - F_j(x)\right)^2dx,
\] where \(G_j(x)\) is the forecasted probability distribution function
for forecast horizon \(j\), and \(F_j(x)\) is the true probability
distribution function for the same period.

\hypertarget{sec-htc}{%
\section{Hierarchical and grouped time series forecasting
techniques}\label{sec-htc}}

There are many applications in healthcare, and in particular in EMS,
where a collection of time series is available. These series are
generally hierarchically organized based on multiple levels such as
area/region, health board and/or are aggregated at different levels in
groups based on nature of demand, priority of demand, or some other
attributes. While series could be strictly hierarchical or only grouped
bases on some attributes, in many situation a more complex structures
arise when attributes of interest are both nested and crossed, having
hierarchical and grouped structure. This is also the case for our
application as discussed in Section~\ref{sec-data}.

\hypertarget{independent-base-forecast}{%
\subsection{Independent (base
forecast)}\label{independent-base-forecast}}

A common practice in healthcare (and EMS) to predict hierarchical and
grouped series relies on producing independent forecasts, also refereed
to as base forecasts, typically by different teams as the need for such
forecasts arise. We observe \(n\) time series at time \(t\), across the
entire hierarchical and grouped structure, written as \(y_t\). The base
forecasts of \(y_{T+h}\) given data \(y_1,\dots,y_T\) are denoted by
\(\hat{y}_h\) for \(h\) steps-ahead for all \(n\) series (\(n=1530\) in
this study). Forecasts generated in this way are not coherent.

\hypertarget{reconciliation-methos}{%
\subsection{Reconciliation methos}\label{reconciliation-methos}}

Traditionally, approaches to produce coherent forecasts for hierarchical
and grouped time series involve using bottom-up and top-down methods by
generating forecasts at a single level and then aggregating or
disaggregating. Top-down methods require having a unique hierarchical
structure to disaggregate forecasts generated at the top level by
proportions. However, given that we have multiple grouped attributes
combined with the hierarchical structure, there is no unique way to
disaggregate top forecasts. Hence the top-down cannot be used in our
application. The recommended approach is to use forecast reconciliation
\citep{hyndman2011optimal}. In the following sections, we first discuss
some notation, and then present bottom-up and forecast reconciliation
approaches used in this study to generate coherent forecasts.

\hypertarget{notations}{%
\subsubsection{Notations}\label{notations}}

Let \(\bm{b}_t\) be a vector of \(n_b\) ``bottom-level'' time series at
time \(t\), and let \(\bm{a}_t\) be a corresponding vector of
\(n_a = n-n_b\) aggregated time series, where \[
  \bm{a}_t = \bm{A}\bm{b}_t,
\] and \(\bm{A}\) is the \(n_a\times n_b\) ``aggregation'' matrix
specifying how the bottom-level series \(\bm{b}_t\) are to be aggregated
to form \(\bm{a}_t\). The full vector of time series is given by \[
 \bm{y}_t = \begin{bmatrix}\bm{a}_t \\\bm{b}_t\end{bmatrix}.
\] This leads to the \(n\times n_b\) ``summing'' or ``structural''
matrix given by \[
  \bm{S} = \begin{bmatrix}\bm{A} \\ \bm{I}_{n_b}\end{bmatrix}
\] such that \(\bm{y}_t = \bm{S}\bm{b}_t\).

\hypertarget{bottom-up-bu-and-linear-reconciliation-methods}{%
\subsubsection{Bottom-up (BU) and linear reconciliation
methods}\label{bottom-up-bu-and-linear-reconciliation-methods}}

Bottom-Up is a simple approach to generate coherent forecasts. It
involves first creating the base forecasts for the bottom level series
(i.e., the most disaggregated series). These forecasts are then
aggregated to the upper levels which naturally results in coherent
forecasts. The BU approach can capture the dynamics of the series at the
bottom level, but these series may be noisy and difficult to forecast.
The approach using only the data at the most disaggregated level, and so
does not utilize all the information available across the hierarchical
and grouped structure.

Forecast reconciliation approaches fill this gap by combining and
reconciling all the base forecasts in order to produce coherent
forecasts. Linear reconciliation methods can be written
\citep{WicEtAl2019} as \[
  \tilde{\bm{y}}_h = \bm{S}(\bm{S}'\bm{W}^{-1}\bm{S})^{-1}\bm{W}^{-1}\hat{\bm{y}}_h,
\] where \(\bm{W}\) is an \(n \times n\) positive definite matrix, and
\(\hat{\bm{y}}_h\) contains the \(h\)-step forecasts of \(\bm{y}_{T+h}\)
given data to time \(T\). Different choices for \(\bm{W}\) lead to
different solutions such as Ordinary Least Squares (OLS), Weighted Least
Squares (WLS) and Minimum Trace (MinT). We use the implementation of
these methods in the fable package in R in the experiment.

\hypertarget{sec-results}{%
\section{Results and discussion}\label{sec-results}}

In this section, we compare the forecasting performance of the Naive,
ETS, GLM and TSGLM models along with the ensemble, using base forecast
and Minimum Trace (MinT) reconciliation methods. We have also computed
the forecast accuracy for Ordinary Least Square (OLS) and Weighted Least
Square (WLS) approaches, along with bottom up forecasting. However, they
are not reported here because their accuracy is outperformed by MinT. We
should also note that forecasts, and consequently their corresponding
errors, are generated for the entire hierarchy and they could be
reported at any level, if required. But to save space, we have reported
only the top level (Total), the bottom level, and the levels
corresponding to Control areas and Health boards. The latter are chosen
because this is where decision-making takes place, so these forecasts
are the most important.

The overall forecasting performance is reported in
Table~\ref{tbl-result}, in which the average forecast accuracy over
horizons 43--84 days (corresponding to the planning horizon) is
presented per model, method and the hierarchical level. Reported
forecast accuracy are averaged across all forecast horizons, rolling
origins and series at each level. Table~\ref{tbl-result} presents both
point and probabilistic forecast accuracy at total, control area, health
board and bottom level series. Point forecast performance are reported
using MASE and MSSE in Table~\ref{tbl-result-1} and
Table~\ref{tbl-result-2}, respectively. Probabilistic forecast accuracy
is reported using CRPS in Table~\ref{tbl-result-3}. The bold entries in
each table identify a combination of method and model that performs best
for the corresponding level (i.e.~each column), based on the smallest
values of accuracy measures.

Table~\ref{tbl-result-1} and 2b show that forecast reconciliation
(i.e.~MinT) improves forecast accuracy at the higher levels of the
hierarchy including total, control area and health board. However, it is
does not result in accuracy improvement at the bottom level series, for
which base forecasts are more accurate. This might be due to the noisy
structure of time series at the bottom level, and possibly due to very
different patterns in the aggregated series. It is also clear from
Table~\ref{tbl-result-1} that the ensemble method improves forecast
accuracy at total, control area and health board. However, this does not
remain valid for bottom series where different individual methods
perform best, depending on the accuracy measure.

\begin{table}

\caption{\label{tbl-result}Average forecast perfomance calculated on the
test sets at forecast horizons \(h=43,\dots,84\) days, with time series
cross validation applied to attended incident data. The best approach is
highlighted in bold.}\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-result-1}Point forecast accuracy using MASE }

{\centering 

\tabularnewline

\centering
\begin{tabular}[t]{llrrrr}
\toprule
\multicolumn{2}{c}{ } & \multicolumn{4}{c}{MASE} \\
\cmidrule(l{3pt}r{3pt}){3-6}
Method & Model & Total & Control areas & Health boards & Bottom\\
\midrule
Base & Naive & 1.139 & 1.059 & 1.047 & 1.019\\
Base & ETS & 0.963 & 0.930 & 0.899 & 1.038\\
Base & GLM & 0.910 & 0.940 & 0.923 & \textbf{1.002}\\
Base & TSGLM & 0.911 & 0.939 & 0.924 & 1.005\\
Base & Ensemble & 0.782 & 0.856 & 0.876 & 1.008\\
\addlinespace
MinT & Naive & 1.138 & 1.059 & 1.047 & 2.651\\
MinT & ETS & 0.877 & 0.916 & 0.915 & 1.289\\
MinT & GLM & 0.848 & 0.901 & 0.902 & 2.493\\
MinT & TSGLM & 0.852 & 0.903 & 0.903 & 2.513\\
MinT & Ensemble & \textbf{0.753} & \textbf{0.844} & \textbf{0.872} & 2.260\\
\bottomrule
\end{tabular}

}

\end{minipage}%
\newline
\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-result-2}Point forecast accuracy using MSSE }

{\centering 

\tabularnewline

\centering
\begin{tabular}[t]{llrrrr}
\toprule
\multicolumn{2}{c}{ } & \multicolumn{4}{c}{MSSE} \\
\cmidrule(l{3pt}r{3pt}){3-6}
Method & Model & Total & Control areas & Health boards & Bottom\\
\midrule
Base & Naive & 1.169 & 1.056 & 1.062 & 1.031\\
Base & ETS & 0.979 & 0.875 & 0.816 & \textbf{0.975}\\
Base & GLM & 0.813 & 0.897 & 0.875 & 1.009\\
Base & TSGLM & 0.822 & 0.901 & 0.875 & 1.050\\
Base & Ensemble & 0.599 & 0.729 & 0.774 & 0.993\\
\addlinespace
MinT & Naive & 1.168 & 1.057 & 1.062 & 2.095\\
MinT & ETS & 0.785 & 0.852 & 0.845 & 0.994\\
MinT & GLM & 0.720 & 0.827 & 0.837 & 1.803\\
MinT & TSGLM & 0.722 & 0.833 & 0.839 & 1.851\\
MinT & Ensemble & \textbf{0.560} & \textbf{0.706} & \textbf{0.765} & 1.557\\
\bottomrule
\end{tabular}

}

\end{minipage}%
\newline
\begin{minipage}[t]{\linewidth}
\subcaption{\label{tbl-result-3}Probabilistic forecast accuracy using CRPS }

{\centering 

\tabularnewline

\centering
\begin{tabular}[t]{llrrrr}
\toprule
\multicolumn{2}{c}{ } & \multicolumn{4}{c}{CRPS} \\
\cmidrule(l{3pt}r{3pt}){3-6}
Method & Model & Total & Control areas & Health boards & Bottom\\
\midrule
Base & Naive & 30.387 & 10.882 & 5.500 & 0.302\\
Base & ETS & 14.309 & 6.074 & 3.476 & 0.244\\
Base & GLM & 15.396 & 6.253 & 3.576 & 0.244\\
Base & TSGLM & 15.316 & 6.227 & 3.575 & 0.245\\
Base & Ensemble & 12.978 & \textbf{5.727} & 3.430 & 0.243\\
\addlinespace
MinT & Naive & 30.368 & 10.902 & 5.498 & 0.313\\
MinT & ETS & 13.515 & 5.967 & 3.547 & \textbf{0.243}\\
MinT & GLM & 13.839 & 5.917 & 3.453 & 0.246\\
MinT & TSGLM & 14.000 & 5.947 & 3.455 & 0.248\\
MinT & Ensemble & \textbf{12.585} & 5.728 & \textbf{3.426} & 0.247\\
\bottomrule
\end{tabular}

}

\end{minipage}%

\end{table}

Table~\ref{tbl-result-3} presents the accuracy of the forecast
distributions measures by CRPS, which considers both forecasting
reliability and interval sharpness. The smaller the value of CRPS, the
better the comprehensive performance. We observe that forecast
reconciliation results in forecast improvement, regardless of the
hierarchical level. The ensemble method is also more accurate for higher
levels, but ETS performs slightly better at the bottom level. While
these results show that forecast reconciliation does not improve
\emph{point} forecasts at the bottom level, Table~\ref{tbl-result-3}
indicates that it generates more accurate \emph{distributional}
forecasts than the base method. This is probably due to the
reconciliation method giving improved forecast accuracy in the tails of
the forecast distribution, which are critical for managing risks.

Overall, our results indicate that forecast reconciliation using the
MinT method provides reliable forecasts, improves upon the base
(unreconciled) forecasts all levels except the bottom level series. But
even there, forecast reconciliation using MinT improves accuracy in the
tails of the distribution.

In addition to the overall forecast accuracy presented in
Table~\ref{tbl-result}, we also report the point and probabilistic
forecast accuracy measures for each forecast horizon in
Figure~\ref{fig-accuracy}. The figure focuses on the hierarchical levels
important for decision-making including total, control area and health
board; however the accuracy could be calculated for any level. We only
illustrate the results of the MinT method, given its strong performance
described in Table~\ref{tbl-result}. For illustration purposes, we
report the average weekly forecast accuracy instead of the daily
forecast horizon, as this reduces the visual noise in the figure. Thus
the x-axis shows horizons from week 1 (\(h= 1,\dots,7\)) to week 12
(\(h= 78,\dots,84\)). The forecast horizon from week 7 to week 12
corresponds to the upcoming planning horizon, which is used by planners
and decision making. For both the point forecast and distributional
accuracy we can see that the ensemble approach performs best across
almost all horizons, with the biggest differences at the highest levels
of aggregation. It is important to highlight that, all forecasting
models outperform the Naive empirical distribution that is used as a
benchmark for both point and probabilistic forecasts.

\begin{figure}[H]

{\centering \includegraphics[width=1\textwidth,height=\textheight]{main_files/figure-pdf/fig-accuracy-1.pdf}

}

\caption{\label{fig-accuracy}Average accuracy by week for 12 weeks using
MinT reconciliation. CRPS is relative to a naive ECDF. MASE and MSSE are
relative to the corresponding values for the training set.}

\end{figure}

\hypertarget{sec-conclusion}{%
\section{Conclusion}\label{sec-conclusion}}

Forecasting problems at Emergency Medical Services often have inherent
hierarchical and grouped structures. For example, looking at time series
of arrival calls in a clinical desk service, verified incidents, or
attended incidents in a country, they could be disaggregated by various
attributes of interest. Total demand in the country could be
disaggregated by region, then within each region by health board, within
each health board, by station/hospital, and so on down to the post code
area. Alternative structures may arise when attributes of interest are
crossed rather than nested. For example, the total demand could be
disaggregated by priority (e.g., Red, Amber, Green) or by nature of
incidents. It is also natural to have a mixed structures, for example
the total demand could be disaggregated by priority and also by health
board.

Despite the inherent hierarchical structure of the forecasting problem
in EMS, the common practice is to produce point forecasts for each time
series independently. This practice may lead to a lack of coordination
and possibly undesirable and conflicting outcomes. Furthermore, due to
the asymmetric impact of resource allocation in this area, quantifying
forecast uncertainty through probabilistic forecasts is also of value as
it enables planners to manage associated risks. In this paper, we
investigate the application of hierarchical forecasting methods for
producing probabilistic forecasts of daily incidents attended up to 84
days ahead, using different forecasting methods.

Our results indicate that forecast reconciliation in EMS can not only
contribute to a more coordinated approach to decision making through
producing coherent forecasts, but also it can result in forecast
accuracy improvement. Our proposed forecasting models, combined with
reconciliation approaches, outperform the empirical distribution
benchmark. We show that a substantial forecast improvement can be
achieved at higher levels of aggregation by applying forecast
reconciliation methods. When a point forecast is of interest at the
bottom level of series, we observe that reconciliation may not improve
the forecast accuracy, if the bottom series are noisy and lack
systematic patterns. However, forecast reconciliation may result in more
forecast results for bottom series, if we are interested in the tails of
forecast distribution rather than just center measures like mean
(i.e.~point forecast). Producing consistent forecast are also crucial
for informing planning activities, we also demonstrate that proposed
models produce consistent forecasts across all forecast horizons.
Therefore, we recommend that forecast reconciliation approaches to be
adopted for routine use in EMS, whenever hierarchical and/or grouped
time series data need to be forecasted. Moreover, we found that using an
ensemble forecasting model, combining all models developed in this
paper, instead of using each individually, works remarkably well for our
mixed hierarchical \& grouped structure.

Further research could investigate the practical benefits of
probabilistic hierarchical forecasting in EMS. Linking forecasts with
its utilities (response time, resource utilization, etc) can offer an
opportunity to maximize benefits through more holistic planning
approach. While, we generated count attend incident for the base
forecast using Poisson regression models, however the reconciles
forecast is snot yet count. This could be also an avenue for further
research.


\renewcommand\refname{References}
  \bibliography{bibliography.bib}


\end{document}
