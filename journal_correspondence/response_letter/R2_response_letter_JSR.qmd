---
title: "Response letter - Manuscript ID JSR-22-468.R1"
bibliography: bibliography.bib
format:
  pdf:
    pdf-engine: pdflatex
    papersize: a4
    geometry: "margin = 2.5cm"
    include-in-header: header.tex
---

Dear Professor Malthouse

Please find enclosed a revised version of our paper submitted for peer review for the *Journal of Service Research*. Your comments have been very much appreciated and we have tried to suitably modify/amend our paper for those comments to be reflected in the revised version.

We quote below the detailed referees’ comments that are followed by our response. In all cases, we point out, where necessary, the corresponding amendments in the new version of the paper and highlighted them in teal (greenish-blue color).


# Editor comment

*My decision on this manuscript was not easy. On the one hand, the reviewers rate the importance of the work as "important" and "very important." They also see "major" potential impact. They acknowledge that you made major changes to the first version of the MS. I personally appreciate you highlighting the changes you made to the manuscript in a blue font and see your substantial improvements to R1. On the other hand the review team feels like many comments from the first round were not addressed. R1 and the AE are asking for model details, clarifications and elaborations. They continue to find typos (R2 notes issues with subscripts and both reviewers mention formatting issues). Simple suggestions like mentioning extended application areas in the introduction, which will help in the positioning of the article for JSR readers, were ignored. They appreciate the example you have added, but suggest adding details. I see these comments as constructive in that their goal is to improve the readability of your manuscript for the JSR and other readers, which will ultimately mean that readers will understand your work so that it realizes its full potential impact. While many of our readers have strong methodological training, JSR is also read by more managerial and policy-oriented scholars; it is important that articles are written in a way to reach both audiences. This expands the reach and impact of your work.*

*In order to gain final acceptance, I ask for you to go back and address the clarifications, details, etc. Please write a point-by-point response and highlight the changes in the manuscript by using a different colored font. I do not plan to send this out for review again. I reserve the right to reject the work if there is not sufficient progress made in addressing the issues identified by the review team in the next submission. (Bahman)*

Response:  

# Associate Editor

We received two very good reviews that came up with justified concern and mixed recommendations. Let me add additional comments.

## AE comments

_Comment 1. The authors need to score higher on the economic insights. Their example did not impress me, and I was hoping to receive more intuition as to why their approach works better._

  **Response:** Thank you for your feedback. In this paper, we introduce a comprehensive framework for probabilistic forecast reconciliation in Emergency Medical Services. Our work not only outlines the rationale behind the proposed approach's suitability for this specific context but also rigorously evaluates its effectiveness through statistical forecast accuracy metrics, as presented in Table 3 and Figure 4. In response to the comment on insights into the economic implications of our approach, we have added the following paragraphs to the paper to further discuss this point:

\textcolor{teal}{Our research establishes a strong basis for future investigations and practical implementation in EMS. Leveraging the hierarchical and grouped structure of demand time series, EMS can use this advanced forecasting framework to generate coherent point and probabilistic forecasts, making the most of all available data at every level of the hierarchy. We acknowledge that a forecast serves a greater purpose beyond its mere existence, ideally enabling the best utility in terms of efficient allocation of medical services, response time, and cost, all informed by the forecast. While we fully appreciate the importance of evaluating forecast quality based on its impact on decision-making processes, it is essential to address the data requirements and methodology involved in measuring this impact. For a comprehensive assessment of the forecasts' implications, access to additional data beyond ambulance demand, covering various decision types, capacity information, constraints in the decision system, and more, becomes necessary. This additional data would offer valuable insights into the specific decisions relying on the forecasts, resulting in a more accurate evaluation of their impact on medical services. Furthermore, measuring the actual impact of forecasts would necessitate an approach that goes beyond forecasting itself. This would involve developing and implementing simulation models capable of replicating decision-making processes based on the forecast inputs. These simulation models would then evaluate the quality of the final decisions, taking into consideration the utilities that are particularly significant in the context of EMS.}

_Comment 2. The authors miss opportunities. I appreciate that the authors summarize previous research in Table 1. Yet, there is nothing in Table 1 that helps the reader understand why the current research has the limitations that the authors state on page 8._

  **Response:** Thank you for your comment. In Table 1, we present three dimensions that highlights the limitations identified in prior research. These dimensions include reconciliation, probabilistic forecasting, and reproducibility. It is noteworthy that there is a notable gap in the existing literature regarding the consideration of probabilistic forecast reconciliation while adhering to the principles of reproducibility. The first column in the table relates to our research, indicating 'YES' in all these dimensions, whereas previous studies have been characterized by a 'NO' in this regard. Table 1 in the previous version had only Reconciliation, and Probabilistic. We now added the reproducibility column to the table, aligning with limitations discussed in the literature section.

_Comment 3. I highly appreciate that the authors intend to provide data and code via their GitHub repository. No doubt, the resulting transparency is a major strength of this manuscript. Yet, the authors could still do a much better job in outlining to the readers that the authors have done a good job._

  **Response:** Thank you. We would like to emphasize that our commitment to transparency and reproducibility goes beyond merely sharing data and code. Our entire paper is authored in R using [Quarto](https://quarto.org/), setting it apart as a uniquely transparent and reproducible workflow and this could be used as an outstanding example of a transparent and reproducible research in academic communities. In this way, we provide not only the code and data but also the entire narrative of the research process. To further highlight that, we have expanded the the reproducibility section in the revised manuscript:

\textcolor{teal}{To enhance transparency and reproducibility, we not only provide data and the code, but also the entire paper that is written in R using [Quarto](https://quarto.org/). All materials to reproduce this paper is available at [github.com/bahmanrostamitabar/forecasting-emergency-medicine](https://github.com/bahmanrostamitabar/forecasting-emergency-medicine). The repository contains the raw data, all R scripts used in experiments, the results used in the paper, as well as the quarto files for producing this paper. Full instructions are provided in the repository.}


_Comment 4.I felt that the authors did not address the following concern that I outlined in the last round of review: “It would also help to have a rather detailed example, maybe even a numerical example, to better describe why separate forecasts at different levels can cause problems. Right now, it sounds plausible that such problems occur, but you are still rather vague concerning the details of these problems.”_

  **Response:** Thank you. We have now added a more detailed but simple example in the introduction based on the ambulance data and added the following text to the revised version of the paper:
  
\textcolor{teal}{To illustrate the problem, let's consider a very simple example where we have an EMS provider with a national level of governance, and two regions (A and B), each with a health board and a station. There is a total national budget to be split between the regions in proportion to the forecast number of incidents in each region. The two regions have very different incident patterns, and so must be forecast using different models. However, the data are noisy at regional level, so the national forecasts are best obtained by summing the demand from the two regions. The resulting national forecasts are not equal to the sum of the regional forecasts, and so are not coherent. In fact, the national forecasts show a decreasing trend in demand, and so the national governing body decides to cut the budget for the next year. But neither of the regional forecasts shows a trend, and so the regions argue that the budget cut is unfair. In addition, Region A has much more variable demand than Region B, and so to cope with periods of peak demand, Region A needs to hold more resources in reserve. So the budget distribution needs to be made in a way that ensures the probability of each region being unable to meet demand is equal. Our solution to this problem is to use a hierarchical forecasting approach that ensures the forecasts are probabilistically coherent. Then any trends or other forecast characteristics at national level will also be reflected in the regional forecasts, and the probabilistic forecasts allow for the different levels of uncertainty in the two regions. Budget can be allocated by controlling the probability of demand exceeding available resources, rather than being simply in proportion to the expected demand.}

_Comment 5. I also had the following comments in the previous round of review: “Make sure that all tables and figures are self-contained” and “If possible, display the number of observations in all tables and figures with statistical results”. Unfortunately, Figure 1 is not self-contained (e.g., abbreviations are not explained). Figure 2 could also contain the correlation and the number of observations._

  **Response:** Thank you for the comment. We have anonymized the name of the health board using two letters (e.g.) that hold no meaningful association, so these are not abbreviations. We have clarified this in the caption of Figure 1.

  With regard to Figure 2, we appreciate the interest in examining correlations. However, we would like to clarify that the purpose of the scatter plot in Figure 2 is not to show the correlation. Each point on the plot corresponds to an individual time series, and the primary objective of this plot is to facilitate a clear understanding of time series features in our dataset such as the strength of trend and seasonality. Introducing correlation values in this specific plot may not add meaningful insights due to the nature of the data representation.

_Comment 6. I was also hoping for an example that not only describes the problem that the authors solve, but that allows us to better understand the basic idea behind the authors’ solution._

  **Response:** Thank you. We've addressed this comment by including a detailed example in the introduction. This addition is designed to clarify the problem and elaborate on the idea behind the forecast reconciliation. We added the following paragraph to the revised version of the paper:

\textcolor{teal}{To illustrate the problem, let's consider a very simple example where we have an EMS provider with a national level of governance, and two regions (A and B), each with a health board and a station. There is a total national budget to be split between the regions in proportion to the forecast number of incidents in each region. The two regions have very different incident patterns, and so must be forecast using different models. However, the data are noisy at regional level, so the national forecasts are best obtained by summing the demand from the two regions. The resulting national forecasts are not equal to the sum of the regional forecasts, and so are not coherent. In fact, the national forecasts show a decreasing trend in demand, and so the national governing body decides to cut the budget for the next year. But neither of the regional forecasts shows a trend, and so the regions argue that the budget cut is unfair. In addition, Region A has much more variable demand than Region B, and so to cope with periods of peak demand, Region A needs to hold more resources in reserve. So the budget distribution needs to be made in a way that ensures the probability of each region being unable to meet demand is equal. Our solution to this problem is to use a hierarchical forecasting approach that ensures the forecasts are probabilistically coherent. Then any trends or other forecast characteristics at national level will also be reflected in the regional forecasts, and the probabilistic forecasts allow for the different levels of uncertainty in the two regions. Budget can be allocated by controlling the probability of demand exceeding available resources, rather than being simply in proportion to the expected demand.}

# Reviewer 1

_**Overall Review:** _

_The authors have made revisions to address some of the concerns raised in the initial review, which has improved certain aspects of the manuscript. Additions have been made to explain the trend and seasonality strength measures, provide the GLM equation, and resolve minor formatting issues. These changes are beneficial. (Bahman)_
  
_However, critical concerns around model specifics, validation methodology, results analysis, and terminology remain unclear or insufficiently addressed. Major issues persist with detailing the ETS configurations, clarifying serial dependence in TSGLM, justifying the naive method’s inclusion, explaining training/testing data splits for tuning, defining the forecast horizon, elaborating the CRPS metric, providing dataset-specific examples for hierarchical forecasting concepts, distinguishing between hierarchical forecasting approaches, validating the comparison technique, and discussing practical implications of non-integer forecasts._

_The lack of clarity and details in these important methodological areas continues to undermine the credibility and reproducibility of the study. Furthermore, the authors do not sufficiently leverage the results to provide managerial insights for EMS planning. More in-depth analysis of the forecast accuracy patterns across timescales, hierarchy levels, and model configurations would strengthen the practical implications._

_In summary, while I acknowledge the efforts to improve the manuscript in certain aspects, there remains a critical need for enhancing model specifics, methodology descriptions, results analysis, and terminology usage._

  **Response:** 



_Comment 1. The authors added brief explanations of the trend and seasonality strength measures in response to Comment #3. While this provides more context, a citation or reference for these specific definitions would further strengthen this section (Bahman)._

  **Response:** 

_Comment 2. The revisions partially address the lack of model detail raised in Comment #4, but some components are still unclear (Bahman):_

  **Response:** 
  
_Comment 2.1. For ETS, it is now stated that an automated algorithm selects the best configuration, but no information is given on what options are available for trend, seasonality, etc. Listing the choices would help the reader. (Bahman)._

  **Response:** 
  
_Comment 2.2. The equation for the GLM model is now provided, but the description still does not mention monthly seasonality. This should be explicitly addressed. (Bahman)_

  **Response:** 

_Comment 2.3. The concept of ”serial dependence” in TSGLM needs more clarification and specificity to the EMS context. (Bahman)_

  **Response:** 
  
_Comment 2.4. The rationale for including the naive method in the ensemble is still not provided. Its apparent poor performance suggests it should be excluded (Rob, Bahman)._

  **Response:** 

_Comment 3. The explanation of the training/validation/testing data split in Comment #5 remains unclear. The authors should explicitly state if tuning is done on the training set only or if a separate validation set is used. (Bahman)_

  **Response:** 
  
_Comment 4. The forecast horizon explanation in Comment #6 is still ambiguous. The time unit (days, weeks, etc.) should be clearly defined. (Bahman)_

  **Response:** 
  
_Comment 5. Comment #7 regarding the CRPS metric lacks sufficient clarification. Explicitly defining concepts like sharpness and miscalibration would strengthen this section. Additionally, more specifics are needed on the forecast distribution derivation. (Rob)_

  **Response:** 
  
_Comment 6. Section 4.2 still lacks concrete examples tying the hierarchical forecasting concepts to the EMS dataset, as noted in Comment #8. This example-based explanation needs enhancement. (Bahman)_

  **Response:** 
  
_Comment 7. Comment #9 about clarifying the differences between various hierarchical forecasting approaches does not seem to be addressed. This terminology is still confusing in Section 4.2.2 and requires revision. (Rob)_

  **Response:** 
  
_Comment 8. Comment #10 questioning the validation approach of comparing base and reconciled forecasts is not addressed. The authors should explain why this is an appropriate evaluation technique. (Rob)_

  **Response:** 

_Comment 9. My concerns in Comment #11 about non-integer forecasts and rounding do not appear to be addressed. This practical issue needs to be discussed. (Bahman)_

  **Response:** 
  
# Reviewer 2

_General comment: The author revised the manuscript upon the review comments and I appreciate the detailed introductions added to the body of the paper.I provide some follow-up comments below for consideration and reference. (Bahman)_

  **Response:** 


_Comment 1. Might be good to at least briefly mention the extended applicability of the idea early in the introduction section. (Bahman)_

  **Response:** 
  
_Comment 2. It is confusing to have the abbreviations BME1 and BME2 listed with the same full name while no explanations or references are given. This is at Section 2, Page 7. (Bahman)_

  **Response:** 
  
_Comment 3. The author added great details to the methods mentioned in Section 3.2, such as the well-explained model specifications of GLM and TSGLM. Make sure typos are corrected, especially notation-wise such as subscripts. (Bahman)_

  **Response:** 
  
_Comment 4. It may be good to consider an alternatively way of providing details to the linear reconciliation method. For instance, the main equation \tilde{y}_h is still missing important reasoning about how it is derived. With some better descriptions of how it is derived, such as an objective function, the follow-up paragraphs for the three methods can be more concisely summarised with better readability. (Rob)_

We have now reworded this section, and added some more details about the objective function which is optimized.

  **Response:** 
  
_Comment 5. The new Section 5.1 provided details about how to obtain and understand the distributional forecasts of the method. Indeed, this can be considered a major selling point of the work, and hence I would always appreciate further addressing and discussions about the probabilistic outperformance of the idea. For example, it might be good to include figures with fitting coverage of the training data, as well as some additional appendix figures for other example series probably at different hierarchy levels. It is not necessary to refer them in the main paper, but some self-explanatory captions should suffice. Besides, comparison with competing methods regarding the same aspect would be a plus. (Bahman)_

  **Response:** 

_Comment 6. There are still formatting issues in the included tables. (Bahman)_

  **Response:** 

# References {#references .unnumbered}